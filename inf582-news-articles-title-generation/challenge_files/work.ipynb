{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rouge_score\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data\n",
    "validation_df = pd.read_csv('data/validation.csv')\n",
    "\n",
    "rouge_scores = []\n",
    "# Initialize Rouge Scorer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'])\n",
    "\n",
    "# Function that generates summaries using LEAD-N\n",
    "def lead_summary(text: pd.core.series.Series, titles: pd.core.series.Series, scorer: rouge_scorer.RougeScorer):\n",
    "    summaries = []\n",
    "    for idx, row in text.items():\n",
    "        sentences = row.split(\".\")\n",
    "        summaries.append([idx, sentences[0] + \".\"])\n",
    "    return summaries\n",
    "\n",
    "# Function that generates summaries using EXT-ORACLE\n",
    "def ext_oracle_summary(text: pd.core.series.Series, titles: pd.core.series.Series, scorer: rouge_scorer.RougeScorer):\n",
    "    summaries = []\n",
    "    for idx, row in text.items():\n",
    "        sentences = row.split(\".\")\n",
    "        reference = titles.iloc[idx]\n",
    "        rs = [scorer.score(sentence, reference)['rougeL'][2] for sentence in sentences]\n",
    "        index, element = max(enumerate(rs), key=itemgetter(1))\n",
    "        summaries.append([idx, sentences[index]])  \n",
    "    return summaries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rouge-L F-Score with LEAD-1:  0.1535873817959459\n",
      "Average Rouge-L F-Score with EXT-ORACLE: 0.31354067145919595\n"
     ]
    }
   ],
   "source": [
    "lead_summaries = lead_summary(validation_df['text'], validation_df['titles'], scorer)\n",
    "ext_oracle_summaries = ext_oracle_summary(validation_df['text'], validation_df['titles'], scorer)\n",
    "\n",
    "lead_rouge = []\n",
    "ext_oracle_rouge = []\n",
    "# Calculate the rouge-l score for each of the generated summaries compared to the original titles\n",
    "for idx, title in validation_df['titles'].items():\n",
    "    lead_rouge.append(scorer.score(lead_summaries[idx][1], title)['rougeL'][2])\n",
    "    ext_oracle_rouge.append(scorer.score(ext_oracle_summaries[idx][1], title)['rougeL'][2])\n",
    "\n",
    "avg_rouge_score_lead = sum(lead_rouge) / len(lead_rouge)\n",
    "avg_rouge_score_ext_oracle = sum(ext_oracle_rouge) / len(ext_oracle_rouge)\n",
    "\n",
    "print(\"Average Rouge-L F-Score with LEAD-1: \", avg_rouge_score_lead)\n",
    "print(\"Average Rouge-L F-Score with EXT-ORACLE:\", avg_rouge_score_ext_oracle)\n",
    "\n",
    "# Store the generated summaries in the Kaggle-accepted format\n",
    "lead_submission_df = pd.DataFrame(lead_summaries, columns=['ID', 'titles'])\n",
    "ext_oracle_submission_df = pd.DataFrame(ext_oracle_summaries, columns=['ID', 'titles'])\n",
    "lead_submission_df.to_csv('lead_submission.csv', index=False)\n",
    "ext_oracle_submission_df.to_csv('ext_oracle_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For summarization in NLP, especially focusing on title generation, various models and techniques can be employed. Here are some of the prominent ones, along with brief explanations of their use cases:\n",
    "\n",
    "### 1. Sequence-to-Sequence (Seq2Seq) Models\n",
    "Seq2Seq models are fundamental in NLP for tasks involving text generation. They work by encoding a source text into a fixed-dimensional context vector and then decoding this vector to produce the output text. For title generation, the input would be the content of an article or document, and the output would be the generated title.\n",
    "\n",
    "### 2. Attention Mechanisms\n",
    "Attention mechanisms improve Seq2Seq models by allowing the decoder to focus on different parts of the input sequence during the generation process, improving the relevance of the generated titles to the content.\n",
    "\n",
    "### 3. Transformer Models\n",
    "Introduced in the paper \"Attention is All You Need\" by Vaswani et al., transformers have become the backbone of modern NLP, surpassing Seq2Seq models in performance. They are based entirely on attention mechanisms and are highly effective in generating summaries and titles due to their ability to capture long-range dependencies in text.\n",
    "\n",
    "### 4. Pre-trained Language Models\n",
    "Pre-trained models such as GPT (Generative Pre-trained Transformer), BERT (Bidirectional Encoder Representations from Transformers), and their variants (e.g., RoBERTa, T5, BART) can be fine-tuned for the specific task of title generation. These models have been trained on vast amounts of text and have an excellent understanding of language, which makes them highly effective for generating coherent and contextually relevant titles.\n",
    "\n",
    "#### Fine-tuning Approach:\n",
    "- **GPT-3 for Direct Generation:** Given a prompt that includes the content, GPT-3 or similar models can directly generate a title based on the given context.\n",
    "- **T5/BART for Text-to-Text Tasks:** T5 and BART are designed explicitly for text-to-text tasks, such as translation, summarization, and, by extension, title generation. They can be fine-tuned by framing the title generation as a summarization problem where the \"summary\" is the title of the input text.\n",
    "\n",
    "### 5. Extractive Summarization Techniques\n",
    "While not directly designed for title generation, extractive summarization models can identify key phrases or sentences within a text. These key elements can inspire or be directly used in generating titles, especially for academic papers or articles where titles are often descriptive and concise.\n",
    "\n",
    "When choosing a model for title generation, consider the specific requirements of your task, such as the desired level of creativity, the importance of context preservation, and the available computational resources. Pre-trained models like GPT-3 or T5, due to their versatility and state-of-the-art performance, are often the go-to choice for tasks requiring high-quality text generation, including title generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:......................................................\n",
      "                                                text  \\\n",
      "0  Thierry Mariani sur la liste du Rassemblement ...   \n",
      "1  C'est désormais officiel : Alain Juppé n'est p...   \n",
      "2  La mesure est décriée par les avocats et les m...   \n",
      "3  Dans une interview accordée au Figaro mercredi...   \n",
      "4  Le préjudice est estimé à 2 millions d'euros. ...   \n",
      "\n",
      "                                              titles  \n",
      "0  L'information n'a pas été confirmée par l'inté...  \n",
      "1  Le maire de Bordeaux ne fait plus partie des R...  \n",
      "2  En 2020, les tribunaux d'instance fusionnent a...  \n",
      "3  Les médecins jugés \"gros prescripteurs d'arrêt...  \n",
      "4  Il aura fallu mobiliser 90 gendarmes pour cett...  \n",
      "validation data:...................................................................\n",
      "                                                text  \\\n",
      "0  Sur les réseaux sociaux, les images sont impre...   \n",
      "1  La vidéo est devenue virale. Elle montre un po...   \n",
      "2  Depuis la présidentielle, il est parfois un pe...   \n",
      "3  Routes endommagées, trains toujours perturbés,...   \n",
      "4  Une enquête menée par le journal l'Obs.La nuit...   \n",
      "\n",
      "                                              titles  \n",
      "0  Le bateau de croisière, long de 275 m, a percu...  \n",
      "1  Le parquet de Paris a annoncé vendredi avoir o...  \n",
      "2  À Trappes (Yvelines), c'est désormais la star....  \n",
      "3  Un homme de 44 ans est porté disparu depuis sa...  \n",
      "4  Son nom n'avait jusque-là jamais été cité dans...  \n",
      "test data:................................................................................................\n",
      "   ID                                               text\n",
      "0   0  L'accès à leurs origines une fois la majorité ...\n",
      "1   1  En 2017, François Bayrou s'était associé à Emm...\n",
      "2   2  Ils ne passeront pas Noël ensemble. Le quotidi...\n",
      "3   3  Dans un message publié pour Noël, le fondateur...\n",
      "4   4  Le suspense a duré jusqu'au bout. Le mardi 4 s...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = 'data/train.csv'\n",
    "data_val = 'data/validation.csv'\n",
    "data_text = 'data/test_text.csv'\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Load the validation data\n",
    "data_val = pd.read_csv(data_val)\n",
    "\n",
    "# Load the test data\n",
    "data_text = pd.read_csv(data_text)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "print(\"training data:......................................................\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"validation data:...................................................................\")\n",
    "print(data_val.head())\n",
    "\n",
    "print(\"test data:................................................................................................\")\n",
    "print(data_text.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecoder and decoder with LSTM layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "device =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, titles, tokenizer, max_length):\n",
    "        self.texts = [torch.tensor(tokenizer.encode(text)[:max_length]) for text in texts]\n",
    "        self.titles = [torch.tensor(tokenizer.encode(title)[:max_length]) for title in titles]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.titles[idx]\n",
    "\n",
    "# Custom function to pad sequences and combine them into a batch\n",
    "def collate_fn(batch):\n",
    "    texts, titles = zip(*batch)\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    titles_padded = pad_sequence(titles, batch_first=True, padding_value=0)\n",
    "    return texts_padded, titles_padded\n",
    "\n",
    "# Define the Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        # Define encoder\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # Define decoder\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # Shared embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Fully connected layer to get output tokens\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        embedded_src = self.embedding(src)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(embedded_src)\n",
    "        \n",
    "        embedded_trg = self.embedding(trg)\n",
    "        decoder_outputs, _ = self.decoder(embedded_trg, (hidden, cell))\n",
    "        \n",
    "        # Prediction\n",
    "        output = self.fc(decoder_outputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from pandas import concat\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text_tuple in data_iter:\n",
    "        text = text_tuple[0]  # Assuming the text is the first element\n",
    "        yield tokenizer(text)\n",
    "\n",
    "combined_texts = concat([data['text'], data_val['text']])\n",
    "\n",
    "# Now, use combined_texts in the iterator\n",
    "vocab = build_vocab_from_iterator(yield_tokens(combined_texts), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, titles, vocab, tokenizer, max_length):\n",
    "        self.texts = [torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long) for text in texts]\n",
    "        self.titles = [torch.tensor([vocab[token] for token in tokenizer(title)], dtype=torch.long) for title in titles]\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx][:self.max_length]\n",
    "        title = self.titles[idx][:self.max_length]\n",
    "        return text, title\n",
    "\n",
    "# Assuming a maximum sequence length for padding/truncation\n",
    "max_length = 100\n",
    "train_dataset = CustomDataset(data['text'], data['titles'], vocab, tokenizer, max_length)\n",
    "val_dataset = CustomDataset(data_val['text'], data_val['titles'], vocab, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/669 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:56<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.4849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:57<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:56<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:57<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.4930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.4703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669/669 [00:55<00:00, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Define the number of epochs for training\n",
    "vocab_size = len(vocab)  # Ensure vocab_size is correctly defined as the length of the vocabulary\n",
    "\n",
    "# Initialize the Seq2Seq model with the correct vocabulary size\n",
    "model = Seq2Seq(vocab_size=vocab_size, embedding_dim=100, hidden_dim=256)\n",
    "\n",
    "# Training setup with optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])  # Assuming '<pad>' is your padding token and is in the vocabulary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for texts, titles in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure trg input to decoder excludes the last token, and trg for calculating loss starts from the second token\n",
    "        output = model(texts, titles[:, :-1])  # Decoder input excludes the last token\n",
    "        \n",
    "        # Reshape output for loss calculation\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)  # Reshape for cross-entropy loss\n",
    "        titles = titles[:, 1:].contiguous().view(-1)  # Target starts from the second token\n",
    "        \n",
    "        loss = criterion(output, titles)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save(model.state_dict(), 'models/seq2seq_model.pth')\n",
    "\n",
    "# loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_index(token, vocab):\n",
    "    # Placeholder for converting a token to its corresponding index\n",
    "    # Adjust this to match how your vocabulary object works\n",
    "    return vocab.get_index(token, default=vocab.get_index(\"<unk>\"))\n",
    "\n",
    "def index_to_token(index, vocab):\n",
    "    # Placeholder for converting an index back to its corresponding token\n",
    "    # Adjust this to match how your vocabulary object works\n",
    "    return vocab.get_token(index, default=\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.vocab.vocab.Vocab'>\n",
      "Vocab()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1500 [00:23<20:59,  1.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summaries\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Generate summaries for the validation data\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m val_summaries \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate the rouge-l score for each of the generated summaries compared to the original titles\u001b[39;00m\n\u001b[0;32m     40\u001b[0m rouge_scores \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[50], line 25\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[1;34m(texts, model, vocab, tokenizer, max_length, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(summary_indices, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 25\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m prediction \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m2\u001b[39m)[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     27\u001b[0m summary_indices\u001b[38;5;241m.\u001b[39mappend(prediction)\n",
      "File \u001b[1;32mc:\\Users\\Ines\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ines\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, trg):\n\u001b[0;32m     33\u001b[0m     embedded_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(src)\n\u001b[1;32m---> 34\u001b[0m     encoder_outputs, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_src\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     embedded_trg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(trg)\n\u001b[0;32m     37\u001b[0m     decoder_outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(embedded_trg, (hidden, cell))\n",
      "File \u001b[1;32mc:\\Users\\Ines\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ines\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ines\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = Seq2Seq(vocab_size=vocab_size, embedding_dim=100, hidden_dim=256)   \n",
    "model.load_state_dict(torch.load('models/seq2seq_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Function to generate summaries using the trained Seq2Seq model\n",
    "# tensor transformation to vocab \n",
    "print(type(vocab))\n",
    "print(vocab)\n",
    "\n",
    "stoi = vocab.get_stoi()  # Get string-to-index mapping\n",
    "itos = vocab.get_itos()\n",
    "\n",
    "def generate_summary(texts, model, vocab, tokenizer, max_length, device):\n",
    "    summaries = []\n",
    "    model.to(device)  # Ensure the model is on the correct device\n",
    "    for text in tqdm(texts):\n",
    "        tokens = tokenizer(text)\n",
    "        indices = [stoi[token] if token in stoi else stoi[\"<unk>\"] for token in tokens]\n",
    "        sequence = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        summary_indices = [stoi['<bos>']]\n",
    "        for _ in range(max_length):\n",
    "            input_tensor = torch.tensor(summary_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(sequence, input_tensor)\n",
    "            prediction = output.argmax(2)[:,-1].item()\n",
    "            summary_indices.append(prediction)\n",
    "            if prediction == stoi['<eos>']:\n",
    "                break\n",
    "        summary_tokens = [itos[idx] for idx in summary_indices]  # Convert indices back to tokens\n",
    "        summary = ' '.join(summary_tokens).replace('<bos>', '').replace('<eos>', '')\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "\n",
    "# Generate summaries for the validation data\n",
    "val_summaries = generate_summary(data_val['text'], model, vocab, tokenizer, max_length, device)\n",
    "\n",
    "# Calculate the rouge-l score for each of the generated summaries compared to the original titles\n",
    "rouge_scores = []\n",
    "for summary, title in zip(val_summaries, data_val['titles']):\n",
    "    scores = scorer.score(summary, title)\n",
    "    rouge_scores.append(scores['rougeL'][2])\n",
    "    \n",
    "avg_rouge_score = sum(rouge_scores) / len(rouge_scores)\n",
    "print(\"Average Rouge-L F-Score:\", avg_rouge_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction-based summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ines\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ines\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  Frequency\n",
      "0        20th         14\n",
      "1     centuri         31\n",
      "2       began          3\n",
      "3           1          2\n",
      "4     januari          1\n",
      "..        ...        ...\n",
      "789     trait          1\n",
      "790   practic          1\n",
      "791  electron          1\n",
      "792    travel          1\n",
      "793   medicin          1\n",
      "\n",
      "[794 rows x 2 columns]\n",
      "sentences\n",
      "['The 20th century began on  1 January 1901 (MCMI), and ended on 31 December 2000 (MM).', '[1][2]  It was the 10th and last century of the 2nd millennium and was marked by new models of scientific understanding, unprecedented scopes of warfare, new modes of communication that would operate at nearly instant speeds, and new forms of art and entertainment.', 'Population growth was also unprecedented,[3] as the century started with around 1.6 billion people, and ended with around 6.2 billion.', '[4]\\nThe 20th century was dominated by significant geopolitical events that reshaped the political and social structure of the globe: World War I, the Spanish flu pandemic, World War II and the Cold War.', 'Unprecedented advances in science and technology defined the modern era, including the advent of nuclear weapons and nuclear power, space exploration, the shift from analog to digital computing and the continuing advancement of transportation, including powered flight and the automobile.', \"The Earth's sixth mass extinction event, the Holocene extinction, continued, and human conservation efforts increased.\", 'Major themes of the century include decolonization, nationalism, globalization and new forms of intergovernmental organizations.', 'Democracy spread, and women earned the right to vote in many countries in the world.', 'Cultural homogenization began through developments in emerging transportation and information and communications technology, with popular music and other influences of Western culture, international corporations, and what was arguably a truly global economy by the end of the 20th century.', 'Poverty was reduced and the century saw rising standards of living, world population growth, awareness of environmental degradation and ecological extinction.', '[5][6] Automobiles, airplanes, and home appliances became common, and video and audio recording saw mass adoption.', 'These developments were made possible by the exploitation of fossil fuel resources, which offered energy in an easily portable form, but also caused concern about pollution and long-term impact on the environment.', 'Humans explored space for the first time, taking their first footsteps on the Moon.', 'Great advances in electricity generation and telecommunications allowed for near-instantaneous worldwide communication, ultimately leading to the Internet.', 'Meanwhile, advances in medical technology resulted in the near-eradication and eradication of many infectious diseases, as well as opening the avenue of biological genetic engineering.', 'Scientific discoveries, such as the theory of relativity and quantum physics, profoundly changed the foundational models of physical science, forcing scientists to realize that the universe was more complex than previously believed, and dashing the hopes (or fears) at the end of the 19th century that the last few details of scientific knowledge were about to be filled in.', \"At the beginning of the period, the British Empire was the world's most powerful nation,[7] having acted as the world's policeman for the past century.\", 'Technological advancements during World War I changed the way war was fought, as new inventions such as tanks, chemical weapons, and aircraft modified tactics and strategy.', 'After more than four years of trench warfare in Western Europe, and up to 22 million dead, the powers that had formed the Triple Entente (France, Britain, and Russia, later replaced by the United States and joined by Italy and Romania) emerged victorious over the Central Powers (Germany, Austria-Hungary, the Ottoman Empire and Bulgaria).', 'In addition to annexing many of the colonial possessions of the vanquished states, the Triple Entente exacted punitive restitution payments from them, plunging Germany in particular into economic depression.', \"The Austro-Hungarian and Ottoman empires were dismantled at the war's conclusion.\", 'The Russian Revolution resulted in the overthrow of the Tsarist regime of Nicholas II and the onset of the Russian Civil War.', \"The victorious Bolsheviks then established the Soviet Union, the world's first communist state.\", \"Fascism, a movement which grew out of post-war angst and which accelerated during the Great Depression of the 1930s, gained momentum in Italy, Germany, and Spain in the 1920s and 1930s, culminating in World War II, sparked by Nazi Germany's aggressive expansion at the expense of its neighbors.\", 'Meanwhile, Japan had rapidly transformed itself into a technologically advanced industrial power and, along with Germany and Italy, formed the Axis powers.', \"Japan's military expansionism in East Asia and the Pacific Ocean brought it into conflict with the United States, culminating in a surprise attack which drew the US into World War II.\", 'After some years of dramatic military success, Germany was defeated in 1945, having been invaded by the Soviet Union and Poland from the East and by the United States, the United Kingdom, Canada, and France from the West.', 'After the victory of the Allies in Europe, the war in Asia ended with the Soviet invasion of Manchuria and the dropping of two atomic bombs on Japan by the US, the first nation to develop nuclear weapons and the only one to use them in warfare.', 'In total, World War II left some 60 million people dead.', \"Following World War II, the United Nations, successor to the League of Nations, was established as an international forum in which the world's nations could discuss issues diplomatically.\", 'It enacted resolutions on such topics as the conduct of warfare, environmental protection, international sovereignty, and human rights.', 'Peacekeeping forces consisting of troops provided by various countries, with various United Nations and other aid agencies, helped to relieve famine, disease, and poverty, and to suppress some local armed conflicts.', 'Europe slowly united, economically and, in some ways, politically, to form the European Union, which consisted of 15 European countries by the end of the 20th century.', 'After the war, Germany was occupied and divided between the Western powers and the Soviet Union.', 'East Germany and the rest of Eastern Europe became Soviet puppet states under communist rule.', 'Western Europe was rebuilt with the aid of the American Marshall Plan, resulting in a major post-war economic boom, and many of the affected nations became close allies of the United States.', \"With the Axis defeated and Britain and France rebuilding, the United States and the Soviet Union were left standing as the world's only superpowers.\", 'Allies during the war, they soon became hostile to one another as their competing ideologies of communism and democratic capitalism proliferated in Europe, which became divided by the Iron Curtain and the Berlin Wall.', 'They formed competing military alliances (NATO and the Warsaw Pact) which engaged in a decades-long standoff known as the Cold War.', 'The period was marked by a new arms race as the USSR became the second nation to develop nuclear weapons, which were produced by both sides in sufficient numbers to end most human life on the planet had a large-scale nuclear exchange ever occurred.', 'Mutually assured destruction is credited by many historians as having prevented such an exchange, each side being unable to strike first at the other without ensuring an equally devastating retaliatory strike.', 'Unable to engage one another directly, the conflict played out in a series of proxy wars around the world—particularly in China, Korea, Cuba, Vietnam, and Afghanistan—as the USSR sought to export communism while the US attempted to contain it.', 'The technological competition between the two sides led to substantial investment in research and development which produced innovations that reached far beyond the battlefield, such as space exploration and the Internet.', 'In the latter half of the century, most of the European-colonized world in Africa and Asia gained independence in a process of decolonization.', 'Meanwhile, globalization opened the door for several nations to exert a strong influence over many world affairs.', \"The US's global military presence spread American culture around the world with the advent of the Hollywood motion picture industry and Broadway, jazz, rock music, and pop music, fast food and hippy counterculture, hip-hop, house music, and disco, as well as street style, all of which came to be identified with the concepts of popular culture and youth culture.\", '[9][10][11] After the Soviet Union collapsed under internal pressure in 1991, most of the communist governments it had supported around the world were dismantled—with the notable exceptions of China, North Korea, Cuba, Vietnam, and Laos—followed by awkward transitions into market economies.', 'Due to continuing industrialization and expanding trade, many significant changes of the century were, directly or indirectly, economic and technological in nature.', \"Inventions such as the light bulb, the automobile, mechanical computers, and the telephone in the late 19th century, followed by supertankers; airliners; motorways; radio communication and broadcasting; television; digital computers; air conditioning; antibiotics; nuclear power; frozen food; microcomputers; the Internet and the World Wide Web; and mobile telephones affected people's quality of life across the developed world.\", 'The quantity of goods consumed by the average person expanded massively.', 'Scientific research, engineering professionalization and technological development—much of it motivated by the Cold War arms race—drove changes in everyday life.', 'At the beginning of the century, strong discrimination based on race and sex was significant in most societies.', 'Although the Atlantic slave trade had ended in the 19th century, movements for equality for non-white people in the white-dominated societies of North America, Europe, and South Africa continued.', 'By the end of the 20th century, in many parts of the world, women had the same legal rights as men, and racism had come to be seen as unacceptable, a sentiment often backed up by legislation.', '[12] When the Republic of India was constituted, the disadvantaged classes of the caste system in India became entitled to affirmative action benefits in education, employment and government.', 'Attitudes toward pre-marital sex changed rapidly in many societies during the sexual revolution of the 1960s and 1970s.', 'Attitudes towards homosexuality also began to change in the later part of the century.', '[13][14]\\nEconomic growth and technological progress had radically altered daily lives.', 'Europe appeared to be at a sustainable peace for the first time in recorded history[citation needed].', 'The people of the Indian subcontinent, a sixth of the world population at the end of the 20th century, had attained an indigenous independence for the first time in centuries.', 'China, an ancient nation comprising a fifth of the world population, was finally open to the world, creating a new state after the near-complete destruction of the old cultural order.', 'With the end of colonialism and the Cold War, nearly a billion people in Africa were left in new nation states.', 'The world was undergoing its second major period of globalization; the first, which started in the 18th century, having been terminated by World War I.', 'Since the US was in a dominant position, a major part of the process was Americanization.', \"The influence of China and India was also rising, as the world's largest populations were rapidly integrating with the world economy.\", 'Terrorism, dictatorship, and the spread of nuclear weapons were pressing global issues.', 'The world was still blighted by small-scale wars and other violent conflicts, fueled by competition over resources and by ethnic conflicts.', 'Disease threatened to destabilize many regions of the world.', 'New viruses such as the West Nile virus continued to spread.', 'Malaria and other diseases affected large populations.', 'Millions were infected with HIV, the virus which causes AIDS.', 'The virus was becoming an epidemic in southern Africa.', 'Based on research done by climate scientists, the majority of the scientific community consider that in the long term environmental problems pose a serious threat.', '[15] One argument is that of global warming occurring due to human-caused emission of greenhouse gases, particularly carbon dioxide produced by the burning of fossil fuels.', '[16] This prompted many nations to negotiate and sign the Kyoto treaty, which set mandatory limits on carbon dioxide emissions.', \"World population increased from about 1.6\\xa0billion people in 1901 to 6.1\\xa0billion at the century's end.\", '[17][18]\\nThe number of people killed during the century by government actions was in the hundreds of millions.', 'This includes deaths caused by wars, genocide, politicide and mass murders.', 'The deaths from acts of war during the two world wars alone have been estimated at between 50 and 80 million.', '[citation needed] Political scientist Rudolph Rummel estimated 262,000,000 deaths caused by democide, which excludes those killed in war battles, civilians unintentionally killed in war and killings of rioting mobs.', '[19] According to Charles Tilly, \"Altogether, about 100 million people died as a direct result of action by organized military units backed by one government or another over the course of the century.', 'Most likely a comparable number of civilians died of war-induced disease and other indirect effects.', '\"[20] It is estimated that approximately 70 million Europeans died through war, violence and famine between 1914 and 1945.', '[21]\\nThe invention of music recording technologies such as the phonograph record, and dissemination technologies such as radio broadcasting, massively expanded the audience for music.', 'Prior to the 20th century, music was generally only experienced in live performances.', 'Many new genres of music were established during the 20th century.', 'Film as an artistic medium was created in the 20th century.', 'The first modern movie theatre was established in Pittsburgh in 1905.', '[37] Hollywood developed as the center of American film production.', 'While the first films were in black and white, technicolor was developed in the 1920s to allow for color films.', 'Sound films were developed, with the first full-length feature film, The Jazz Singer, released in 1927.', 'The Academy Awards were established in 1929.', 'Animation was also developed in the 1920s, with the first full-length cel animated feature film Snow White and the Seven Dwarfs, released in 1937.', 'Computer-generated imagery was developed in the 1980s, with the first full-length CGI-animated film Toy Story released in 1995.', 'Video games—due to the great technological steps forward in computing since the second post-war period—are one of the new forms of entertainment that emerged in the 20th century alongside films.', 'Multiple new fields of mathematics were developed in the 20th century.', 'In the first part of the 20th century, measure theory, functional analysis, and topology were established, and significant developments were made in fields such as abstract algebra and probability.', \"The development of set theory and formal logic led to Gödel's incompleteness theorems.\", 'Later in the 20th century, the development of computers led to the establishment of a theory of computation.', '[42] Computationally-intense results include the study of fractals[43] and a proof of the four color theorem in 1976.', '[44]\\nOne of the prominent traits of the 20th century was the dramatic growth of technology.', 'Organized research and practice of science led to advancement in the fields of communication, electronics, engineering, travel, medicine, and war.']\n",
      "printing the sentence scores\n",
      "    Sentence      Score\n",
      "0    The 20t  17.578947\n",
      "1    [1][2]   13.057143\n",
      "2    Populat  19.272727\n",
      "3   [4]\\nThe  16.785714\n",
      "4    Unprece  12.724138\n",
      "..       ...        ...\n",
      "87   The dev  12.666667\n",
      "88   Later i  27.666667\n",
      "89   [42] Co   8.041667\n",
      "90  [44]\\nOn  15.400000\n",
      "91   Organiz  18.190476\n",
      "\n",
      "[92 rows x 2 columns]\n",
      "printing the threshold\n",
      "17.39710064261602\n",
      " Democracy spread, and women earned the right to vote in many countries in the world. Humans explored space for the first time, taking their first footsteps on the Moon. At the beginning of the period, the British Empire was the world's most powerful nation,[7] having acted as the world's policeman for the past century. After the victory of the Allies in Europe, the war in Asia ended with the Soviet invasion of Manchuria and the dropping of two atomic bombs on Japan by the US, the first nation to develop nuclear weapons and the only one to use them in warfare. In total, World War II left some 60 million people dead. After the war, Germany was occupied and divided between the Western powers and the Soviet Union. With the Axis defeated and Britain and France rebuilding, the United States and the Soviet Union were left standing as the world's only superpowers. At the beginning of the century, strong discrimination based on race and sex was significant in most societies. With the end of colonialism and the Cold War, nearly a billion people in Africa were left in new nation states. Terrorism, dictatorship, and the spread of nuclear weapons were pressing global issues. Millions were infected with HIV, the virus which causes AIDS. Later in the 20th century, the development of computers led to the establishment of a theory of computation.\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as BeautifulSoup\n",
    "import urllib.request  \n",
    "\n",
    "#fetching the content from the URL\n",
    "fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')\n",
    "\n",
    "article_read = fetched_data.read()\n",
    "\n",
    "#parsing the URL content and storing in a variable\n",
    "article_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')\n",
    "\n",
    "#returning <p> tags\n",
    "paragraphs = article_parsed.find_all('p')\n",
    "\n",
    "article_content = ''\n",
    "\n",
    "#looping through the paragraphs and adding them to the variable\n",
    "for p in paragraphs:  \n",
    "    article_content += p.text\n",
    "\n",
    "\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table\n",
    "\n",
    "\n",
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "\n",
    "       \n",
    "\n",
    "    return sentence_weight\n",
    "\n",
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "    #print (frequency_table) as pandas dataframe\n",
    "    print(pd.DataFrame(frequency_table.items(), columns=['Word', 'Frequency']))\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    print(\"sentences\")\n",
    "    sentences = sent_tokenize(article)\n",
    "    print(sentences)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "    print(\"printing the sentence scores\"    )\n",
    "    print(pd.DataFrame(sentence_scores.items(), columns=['Sentence', 'Score']))\n",
    "    \n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "    print(\"printing the threshold\")\n",
    "    print(threshold)\n",
    "    \n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    summary_results = _run_article_summary(article_content)\n",
    "    print(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur les réseaux sociaux, les images sont impressionnantes. Dimanche matin à Venise, l'équipage du MSC Opéra a perdu le contrôle du paquebot, à son arrivée dans le port de la cité des Doges. Le navire, qui peut contenir plus de 2.600 passagers, est venu heurter le quai auquel il voulait s'arrimer. Le paquebot a raclé le quai sur plusieurs mètres, suscitant la panique des personnes à terre, avant de percuter un autre bateau touristique, le Michelangelo, stoppant ainsi sa course. Des témoins ont filmé la scène. Les vidéos montrent des touristes courant pour tenter de fuir le paquebot, qui ne semble pas vouloir s'arrêter. Quatre personnes ont été blessées dans cet accident : deux légèrement, tandis que les deux autres ont été transportées à l'hôpital pour des examens. L'incident s'est produit à San Basilio-Zaterre, dans le canal de la Giudecca, où de nombreux navires de croisière s'arrêtent pour permettre à leurs passagers de visiter Venise.Selon le quotidien italien Corriere della Serra, cette course folle serait due aux forts courants et à la rupture de l'un des câbles qui reliait le navire au remorqueur, qui l'aidait à entrer dans le canal.\n",
      "           Word  Frequency\n",
      "0           sur          2\n",
      "1            le         16\n",
      "2       réseaux          1\n",
      "3       sociaux          1\n",
      "4             ,         15\n",
      "..          ...        ...\n",
      "120     reliait          1\n",
      "121          au          1\n",
      "122  remorqueur          1\n",
      "123    l'aidait          1\n",
      "124      entrer          1\n",
      "\n",
      "[125 rows x 2 columns]\n",
      "sentences\n",
      "['Sur les réseaux sociaux, les images sont impressionnantes.', \"Dimanche matin à Venise, l'équipage du MSC Opéra a perdu le contrôle du paquebot, à son arrivée dans le port de la cité des Doges.\", \"Le navire, qui peut contenir plus de 2.600 passagers, est venu heurter le quai auquel il voulait s'arrimer.\", 'Le paquebot a raclé le quai sur plusieurs mètres, suscitant la panique des personnes à terre, avant de percuter un autre bateau touristique, le Michelangelo, stoppant ainsi sa course.', 'Des témoins ont filmé la scène.', \"Les vidéos montrent des touristes courant pour tenter de fuir le paquebot, qui ne semble pas vouloir s'arrêter.\", \"Quatre personnes ont été blessées dans cet accident : deux légèrement, tandis que les deux autres ont été transportées à l'hôpital pour des examens.\", \"L'incident s'est produit à San Basilio-Zaterre, dans le canal de la Giudecca, où de nombreux navires de croisière s'arrêtent pour permettre à leurs passagers de visiter Venise.Selon le quotidien italien Corriere della Serra, cette course folle serait due aux forts courants et à la rupture de l'un des câbles qui reliait le navire au remorqueur, qui l'aidait à entrer dans le canal.\"]\n",
      "printing the sentence scores\n",
      "  Sentence     Score\n",
      "0  Sur les  4.000000\n",
      "1  Dimanch  3.769231\n",
      "2  Le navi  3.520000\n",
      "3  Le paqu  3.000000\n",
      "4  Des tém  4.000000\n",
      "5  Les vid  4.000000\n",
      "6  Quatre   3.428571\n",
      "7  L'incid  2.310345\n",
      "printing the threshold\n",
      "3.5035183781735504\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/validation.csv')\n",
    "\n",
    "# Assuming each row in the CSV contains an article or paragraph in a column named 'text'\n",
    "# Let's summarize the first article/paragraph for demonstration\n",
    "article_content = data.iloc[0]['text']\n",
    "print(article_content)\n",
    "\n",
    "# Now we can apply the summarization code to `article_content`\n",
    "summary_results = _run_article_summary(article_content)\n",
    "print(summary_results)\n",
    "print(len(summary_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
